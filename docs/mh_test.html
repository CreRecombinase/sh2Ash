<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Jean Morrison" />

<meta name="date" content="2017-07-20" />

<title>Testing using MH/LOO for model selection</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-1.1/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-1.1/highlight.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Sherlock2 model using Ash</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/jdblischak/workflowr">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Testing using MH/LOO for model selection</h1>
<h4 class="author"><em>Jean Morrison</em></h4>
<h4 class="date"><em>July 20, 2017</em></h4>

</div>


<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>I am exploring different methods of model selection for the sherlock problem. We are attempting to distinguish between null, causal, and partial sharing models. Previously I have used BIC but that probably isn’t the best strategy. In particular, it is only based on the ML (or MAP) estimates and the corresponding likelihood.</p>
<p>Here I am looking at trying to sample from the posterior distribution of the parameters in order to get more Bayesian measures of model fit. I am using the R package <code>MHadaptive</code> to run an adaptive Metropolis-Hastings algorithm. I first attempted to use STAN but found that sampling was prohibitively slow due to slow evaluation of the likelihood. Since I have already implemented an efficient calculation of the likelihood in C++ (call-able from R), I found it was much more efficient to use the R package for sampling. So far I haven’t figured out if there is a way to get STAN to use my C++ code.</p>
<p>There are currently two limitations of this method:</p>
<ol style="list-style-type: decimal">
<li>Mixing proportions for SNP effect sizes must be fixed. This is because the mixing proportions lie on a simplex and <code>MHadaptive</code> can’t really sample from a simplex (that I have found, so far). There might be a work-around for this in the future. In this document, I conduct some experiments in which the mixing proportions are known. In the future I will see how performance is using fixed but estimated proportions.</li>
<li>The models I am currently comparing only allow effects in one direction. It probably is not too hard to allow effects in both directions. For simplicity, for now I am only using one direction.</li>
</ol>
</div>
<div id="models" class="section level2">
<h2>Models</h2>
<p>One graphical representation of the model we are considering is here:</p>
<p><img src="tfactor_simple.png" width="400"></p>
<p>There are <span class="math inline">\(p\)</span> SNPs, each of which can act on trait 1, trait 2, or both. The distribution of effect sizes of SNPs on the two traits for now is assumed known (see limitation 1 above). Of the SNPs acting on trait 1, a proportion <span class="math inline">\(1-q\)</span> between 0 and 1 act directly on trait 1 without contributing to trait 2, while the remainng <span class="math inline">\(q\)</span> act through a shared factor that also acts on trait 2 with effect size <span class="math inline">\(b\)</span>.</p>
<p>The null model, in which the two traits are not related at all, is represented by <span class="math inline">\(q=0\)</span> and <span class="math inline">\(b=0\)</span>. It is worth noting that if either <span class="math inline">\(q\)</span> or <span class="math inline">\(b\)</span> is equal to 0, the other parameter is not identifiable or meaningful. The causal model is represented by <span class="math inline">\(q = 1\)</span> and <span class="math inline">\(b \neq 0\)</span>. Partial sharing is indicated by other values of the parameters.</p>
<p>Since we observe summary statistics rather than true effects, we include an additional parameter <span class="math inline">\(\rho\)</span> in all models to capture correlation in the noise of the parameter estimates between the two traits. This parameter is disucssed further <a href="two_factor.html">here</a>.</p>
<div id="likelihood" class="section level3">
<h3>Likelihood</h3>
<p>Let <span class="math inline">\(\hat{\beta}_{ij}\)</span> be the estimated effect size of SNP <span class="math inline">\(j\)</span> on trait <span class="math inline">\(i\)</span> and <span class="math inline">\(s_{ij}\)</span> be the corresponding standard error. Assuming no measuement error in the estimation of <span class="math inline">\(s_{ij}\)</span>, the likelihood of the observed pair of estimates <span class="math inline">\((\hat{\beta}_{1j}, \hat{\beta}_{2j})\)</span> is</p>
<p><span class="math display">\[
P\left( \begin{pmatrix}\hat{\beta}_{1j}\\ \hat{\beta}_{2j}\end{pmatrix}; \rho, b, q, s_{1j}, s_{2j}   \right) = q\left\lbrace \sum_{k=1}^{K} \pi_k N\left(\begin{pmatrix}\hat{\beta}_{1j}\\ \hat{\beta}_{2j}\end{pmatrix}; \begin{pmatrix}0\\0\end{pmatrix}, A(0, b)U_k A(0, b)^{T} + S(\rho, s_{1j}, s_{2j}) \right)\right \rbrace  +\\ (1-q)\left \lbrace  \sum_{k=1}^{K} \pi_kN\left(\begin{pmatrix}\hat{\beta}_{1j}\\ \hat{\beta}_{2j}\end{pmatrix}; \begin{pmatrix}0\\0\end{pmatrix}, U_k  + S(\rho, s_{1j}, s_{2j}) \right)\right\rbrace
\]</span> Where <span class="math inline">\(U_k\)</span> and <span class="math inline">\(\pi_k\)</span> are known variance matrices and mixing componenets for the SNP effects,</p>
<p><span class="math display">\[
A(a, b) = \begin{pmatrix} 1 &amp; a \\ b &amp; 1\end{pmatrix}
\]</span> and <span class="math display">\[
S(\rho, s_{1j}, s_{2j}) = \begin{pmatrix} s_{1j}^2 &amp; \rho s_{1j}s_{2j}\\
 \rho s_{1j}s_{2j} &amp; s_{2j}^2
\end{pmatrix}
\]</span></p>
<p>We can then write <span class="math display">\[
L(\rho, b, q) = \prod_{j=1}^{p} P\left( \begin{pmatrix}\hat{\beta}_{1j}\\ \hat{\beta}_{2j}\end{pmatrix}; \rho, b, q, s_{1j}, s_{2j}   \right)^{w_j}
\]</span> where <span class="math inline">\(w_j\)</span> are weights that account for LD.</p>
</div>
<div id="priors" class="section level3">
<h3>Priors</h3>
<p>In order to ensure identifiability, the prior on <span class="math inline">\(b\)</span> should have no or very little mass at zero. In this document, I will use the non-local normal moment prior propsed by Johnson and Rossell (2010). For this problem, we assume that we have a good idea of which direction any possible causal effect will go and that effect size estimates are scaled so that it is likely that <span class="math inline">\(\vert b \vert &lt; 1\)</span>. The prior <span class="math display">\[
\pi_b(b) = \frac{b^2}{0.4^2}N(b; 0, 0.4)
\]</span> has the following shape:</p>
<pre class="r"><code>f &lt;- function(t, sigma){
(t/sigma)^2*dnorm(t, 0, sigma)}
curve(f(x, 0.4), from=-4, to=4)</code></pre>
<p><img src="mh_test_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>This prior places 90% of its mass between -1 and 1 and 33% of its mass between -0.5 and 0.5. In ohter cases, it may be necessary to change the scale parameter of the normal moment prior.</p>
<p>We place a mildly informative prior on <span class="math inline">\(z = \text{arctanh}(\rho)\)</span> with a mode at zero. We use <span class="math display">\[ \pi_z(z) = N(z; 0, 0.5)\]</span></p>
<p>I considered three different priors for <span class="math inline">\(q\)</span>: a non-local prior that has most of its mass away from 0 and 1 which correspond to the null and causal models respectively, a flat prior, and a prior that places most of its mass on small values (the Beta<span class="math inline">\((1, 3)\)</span> distribution which has 87.5% of its mass less than 0.5). I was only able to run the sampler using the non-local prior due to computational issues finding the gradient of the likelihood.</p>
<p>For simplicity, the priors for the three parameters are independent.</p>
</div>
</div>
<div id="experiments" class="section level2">
<h2>Experiments</h2>
<p>We start with a set of experiments that should be easy: On average, there are 500 SNPs effecting trait 1 with effect size distributed <span class="math inline">\(N(0, 0.15)\)</span>. There are on average 1000 SNPs effecting trait 2 with effect size for direct acting SNPs distributed <span class="math inline">\(N(0, 0.05)\)</span>. This gives an average heritability of about 72% for trait 1 and 37% for trait 2. There are 10,000 SNPs total.</p>
<p>Below I will present results in each of 15 settings with <span class="math inline">\(q\)</span> taking on values 0, 0.25, 0.5, 0.75, and 1 and <span class="math inline">\(b\)</span> taking on values 0.2, 0.5, and 1. The settings with <span class="math inline">\(q=0\)</span> (<span class="math inline">\(b\)</span> is irrelevent for these) are equivalent to the null model while <span class="math inline">\(q=1\)</span> is equivalent to the causal model.</p>
<div id="model-comparison-results" class="section level3">
<h3>Model comparison results</h3>
<p>Here I consider three methods of comparing models</p>
<ol style="list-style-type: decimal">
<li><p>DIC (Deviance information criterion). This is relatively easy to compute. For each sample, <span class="math inline">\(\theta^s\)</span> of parameters from the posterior, we must calculated <span class="math inline">\(p(\text{data} | \theta^s)\)</span>. Lower values of DIC indicate a better fit. Below I present results in which we simply select the model with the lowest DIC.</p></li>
<li><p>LOOIC. This is the information criterion based on leave-one-out cross validation (LOO). It can be calculated using the <code>loo</code> package in R but is fairly computationally intensive. In order to make this computation we need to calculate <span class="math inline">\(p(\text{data}_n \vert \theta^s)\)</span> for every sample from the posterior, for every SNP. With many SNPs, this will prove impossible. The LOOIC can also be calculated using a random subsample of SNPs. I will need to explore this possibility further however because most of the information about which model is best will be contained in a small subset of SNPs. This means that a random sample could be unreliable. Below I show results in which the model with the lowest LOOIC value is selected.</p></li>
<li><p>Comparison of LOO values. This model selection method uses the LOO results but takes advantage of the fact that some confidence can be assigned to the difference in elpd (which is the quantity estimated by LOO) between two models. Below I use the following rules:</p></li>
</ol>
<ul>
<li>Model A is considered ``better’’ than model B if <span class="math inline">\(\widehat{\Delta elpd}_{AB}/se(\widehat{\Delta elpd}_{AB}) &gt; 1.93\)</span> (that is - with good confidence we can say that the elpd for model A is higher than the elpd for model B).</li>
<li>If neither the causal model nor the shared model is better than the null model, we choose the null model. Note that either of the non-null models may have a slightly larger elpd (or lower LOOIC) than the null model but not meet the criterion above to be considered ``better’’.</li>
<li>If one or both of the non-null models is better than the null model, we compare the shared and causal model. If the causal model is better, we choose it. Otherwise we choose the shared model.</li>
</ul>
<p>Note that this system makes it harder to choose the non-null models over the null model and harder to choose the causal model over the shared model.</p>
<p>Before running these experiments, I felt that method 3 would be the best, however, given the difficulty of calculating the elpd based on LOO, was hopeful that comparison based on DIC would yield similar results.</p>
<p>Model comparison results of the experiments are shown below. The value of <span class="math inline">\(b\)</span> increases reading across collumns (left: 0.2, middle: 0.5, right: 1). In each plot, the <span class="math inline">\(x\)</span>-axis is <span class="math inline">\(q\)</span> and the <span class="math inline">\(y\)</span> axis is the proportion of simulations assigned to each model. Rows of plots correspond to different model selection procedures (top: DIC, middle: LOOIC, bottom: LOO comparison) :</p>
<p><img src="results_models.png" width="800"></p>
<p>Based on these results, the LOO comparison method does apear to be the best model selection method (third row of plots). It always chooses the null model when <span class="math inline">\(q=0\)</span> and usually chooses the shared model when <span class="math inline">\(q = 0.25\)</span>, 0.5 or 0.75. However, disturbingly, there are several false slobielections of the causal model when <span class="math inline">\(b=1\)</span> and <span class="math inline">\(q\)</span> is small and the power to choose the causal model when <span class="math inline">\(q=1\)</span> is low. Since these data have fairly strong signal, we would hope for better performance. Additionally, we should have better power for larger values of <span class="math inline">\(b\)</span> which we don’t observe. To explore these quesitons, I looked more closely at the poseterior samples.</p>
</div>
<div id="trace-plots" class="section level3">
<h3>Trace plots</h3>
<p>For each of the 150 simulated data sets described above and for each model, I ran three chains of length 3000, discarding the frist 1000 samples and then thinning by taking avery fifth sample. The starting point for each chain is sampled randomly from the prior. I examined trace plots for each simulation, checking for good mixing of the three chains and that the chains appeared to have reached a stationary distribution. In many cases, the MH algorithm appeared to have converged correctly in all chains. However, in some cases, it appears that the likelihood in the shared model is bimodal and that many of our false postives are these cases.</p>
<p>For example, in the setting <span class="math inline">\(q=0.5\)</span> and <span class="math inline">\(b=1\)</span>, there are four simulations for which the causal model seems to fit better than the shared model. Here is the trace plot for one of these simulations:</p>
<p><img src="q_0.5_b_1_2.png" width="800"></p>
<p>The first row of plots shows posterior samples of <span class="math inline">\(z = \text{tanh}(\rho)\)</span> from the null model. The second row shows samples of <span class="math inline">\(z\)</span> and <span class="math inline">\(b\)</span> from the causal model. The third row shows samples of <span class="math inline">\(z\)</span>, <span class="math inline">\(b\)</span>, and <span class="math inline">\(\text{logit}(q)\)</span> from the shared model. In the null and causal models, all three chains seem to be sampling from the same distribution. In the shared model, two chains draw valuse of <span class="math inline">\(b\)</span> and <span class="math inline">\(q\)</span> close to the true values, while chain 3 is sampling values of <span class="math inline">\(b\)</span> around -2.8 and values of <span class="math inline">\(q\)</span> close to 0.08.</p>
<p>Looking more closely at the data for this simulation, we see that there is a very clear trend in the pairs of z-scores but, looking at the log-likelihood for the sharing model, there is a local mode close to <span class="math inline">\(b=-3\)</span> and <span class="math inline">\(\text{logit}(q) = -2.4\)</span>.</p>
<p><img src="example_z_scores.png" width="400"> <img src="example_loglik.png" width="400"></p>
<p>One possible solution to this problem might be to always start chains close to the MAP estimate rather than at random locations sampled from the prior.</p>
</div>
</div>
<div id="results-always-starting-chains-at-map" class="section level2">
<h2>Results always starting chains at MAP</h2>
<p>If we always start the chains at the MAP, we get the following model classification results (rows and columns and axes of this plot are the same as the equivalent plot above):</p>
<p><img src="results_models_map_start.png" width="800"></p>
<p>Using the LOO Compare method, we have eliminated all false postives! However, we still have low power to choose the causal model when <span class="math inline">\(q=1\)</span>. Given that the causal model always has the lowest LOOIC in these settings, we may be being too conservative. It is possible for the shared model to be very similar to the causal model by estimating <span class="math inline">\(q\)</span> to be large. We could consider a model selection scheme in which we choose the causal model if it is better than the shared model <em>or</em> if the two models have similar elpd and the shared model estimates <span class="math inline">\(q\)</span> to be above a certain threshold.</p>
<p>The following plots show the posterior 90% credible intervals for <span class="math inline">\(q\)</span> from the shared model. The first plot is for data generated with <span class="math inline">\(q = 0\)</span> (i.e. under the null model). The other three plots are respectively for each value of <span class="math inline">\(b\)</span>. Colors indicate the value of <span class="math inline">\(q\)</span>. <img src="q_cis_map_start.png" width="800"></p>
<p>Here are the equivalent plots for the posterior distribution of <span class="math inline">\(b\)</span> from the shared model.</p>
<p><img src="b_cis_map_start.png" width="800"></p>
</div>

<hr>
<p>
    This <a href="http://rmarkdown.rstudio.com">R Markdown</a> site was created with <a href="https://github.com/jdblischak/workflowr">workflowr</a>
</p>
<hr>

<!-- To enable disqus, uncomment the section below and provide your disqus_shortname -->

<!-- disqus
  <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'rmarkdown'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
-->


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
