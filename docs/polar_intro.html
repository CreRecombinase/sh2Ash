<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Jean Morrison" />


<title>Understaning patterns of sharing by estimating the distribution of angles</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-1.1/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-1.1/highlight.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Sherlock2 model using Ash</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/jdblischak/workflowr">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Understaning patterns of sharing by estimating the distribution of angles</h1>
<h4 class="author"><em>Jean Morrison</em></h4>
<h4 class="date"><em>October 5, 2017</em></h4>

</div>


<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>This document describes some first explorations of a new approach to the problem of understanding patterns of genetic sharing using association summary statistics for a pair of traits.</p>
<p>Let <span class="math inline">\(\beta_{i,j}\)</span> and <span class="math inline">\(\hat{\beta}_{i,j}\)</span>, <span class="math inline">\(i \in 1, \dots, p\)</span>, <span class="math inline">\(j=1,2\)</span> be the true and estimated marginal effect sizes for SNPs <span class="math inline">\(i\)</span> on trait <span class="math inline">\(j\)</span>. The motivating idea for this approach is that if we knew <span class="math inline">\(\beta_{i,j}\)</span>, we could summarize the pattern of genetic sharing between the two traits by looking at the distribution of <span class="math inline">\(\beta_{i,1}/\beta_{i,2}\)</span> or equivalently, by summarizing the distribution of the angle between pairs of effects and the <span class="math inline">\(x\)</span>(trait 1)-axis, <span class="math inline">\(\theta_i = tan^{-1}(\beta_{i,2}/\beta_{i,1})\)</span>. There are some advantages to focusing on the distribution of <span class="math inline">\(\theta_i\)</span>: i) It’s support is finite, between <span class="math inline">\(-\pi\)</span> and <span class="math inline">\(\pi\)</span> and ii) If the true effect sizes are sparse and some SNPs effect only trait 2 then the distribution of the ratio has positive mass at <span class="math inline">\(\infty\)</span>.</p>
<p>If the true effect sizes are sparse, there will be many SNPs for which <span class="math inline">\(\beta_{i,1} = \beta_{i,2} = 0\)</span>. In polar coordinates, this is equivalent to the condition that <span class="math inline">\(r_i \equiv \sqrt{\beta_{i,1}^{2} + \beta_{i,2}^2} = 0\)</span>. In this case, <span class="math inline">\(\theta_i\)</span> is not defined and the SNP is irrelevant to our question. Theferore, the distribution that is of most interest is actually the conditional distribution of <span class="math inline">\(\theta \vert r &gt; 0\)</span>.</p>
<p>Since, in most cases, the allele coding for each SNP is aribitrary, we can simplify the problem by constraining <span class="math inline">\(\theta\)</span> to lie between <span class="math inline">\(-\pi/2\)</span> and <span class="math inline">\(\pi/2\)</span>. Changing the allele coding is equivalent to increasing (or decreasing) the angle of the pair of effects by <span class="math inline">\(\pi\)</span>. That is, if the pair <span class="math inline">\((\beta_{i,1}, \beta_{i,2})\)</span> has an angle of <span class="math inline">\(\pi/5\)</span> and we flip the minor and major allele, the new pair of effects will have an angle of <span class="math inline">\(-4\pi/5\)</span>. Thus, it is reasonable to assume that <span class="math inline">\(p[\theta_i = t] = p[\theta_i = t + \pi]\)</span>. Without losing any information, we can choose to orient all the SNPs so that <span class="math inline">\(\beta_{i,1}\)</span> is positive constraining <span class="math inline">\(\theta_i\)</span> to the interval <span class="math inline">\([-\pi/2, \pi/2]\)</span>.</p>
<div id="possible-distributions-of-theta-vert-r-0-under-some-sharing-models" class="section level3">
<h3>Possible distributions of <span class="math inline">\(\theta \vert r &gt; 0\)</span> under some sharing models</h3>
<p>Before discussing methods to estimate the distribution of <span class="math inline">\(\theta\)</span> from summary staistics, I explore some possible patterns and how they might be interpreted.</p>
<p>If there is no sharing between the two traits and no pleiotropy then all of the true effects will be zero for one or both traits. This means that for every SNP, <span class="math inline">\(\theta_i = 0\)</span> (the SNP effects only trait 1) or <span class="math inline">\(\theta_i = \pm \pi/2\)</span> (the SNP effects only trait 2).</p>
<p><img src="polar_intro_files/figure-html/one-1.png" width="672" /></p>
<p>Observing many SNPs with <span class="math inline">\(\theta_i\)</span> between 0 and <span class="math inline">\(\pi/2\)</span> indicates that there is positive genetic correlation bewteen the traits while many SNPs with <span class="math inline">\(\theta_i\)</span> between 0 and <span class="math inline">\(-\pi/2\)</span> indicates negative correlation between the traits.</p>
<p>In trait 1 directly, causally effects trait 2 and there are no additional pleiotropic effects then we expect there to be a constant <span class="math inline">\(\lambda\)</span> such that <span class="math inline">\(\beta_2 = \lambda \beta_1\)</span> whenever <span class="math inline">\(\beta_1 \neq 0\)</span>. There may be SNPs that effect trait 2 through other mechanisms, but all SNPs effecting trait 1 should also have a non-zero effect on trait 2. This pattern looks like this:</p>
<p><img src="polar_intro_files/figure-html/two-1.png" width="672" /></p>
<p>We see that there  mass at zero but there is a spike between 0 and <span class="math inline">\(\pi/2\)</span>. If trait 2 causally effects trait 1, we expect to observe no mass at <span class="math inline">\(\pm \pi/2\)</span>.</p>
<p>If there is no causal relationship between the traits but they share many regulatory factors in common, we might expect there to be many pleiotropic SNPs with non-zero effects on both traits. We would still expect to see many SNPs effecting only one of the two traits and there may not be a consistent direction or ratio of effects sizes.</p>
<p><img src="polar_intro_files/figure-html/three-1.png" width="672" /></p>
<p>Under this sharing pattern, there is positive mass at both 0 and <span class="math inline">\(\pm \pi/2\)</span> but there are some effects distributed between these values as well.</p>
<p>By looking at these patterns, we see that there are several important pieces of information we can learn from the distribution of <span class="math inline">\(\theta_i \vert r_i &gt; 0\)</span>:</p>
<ul>
<li>What proportion of SNPs effect only trait 1/2 and what proportion effect both traits? Observing no SNPs effecting only trait 1/2 provides evidence in favor of a causal relationship. Seeing a large weight at 0 provides evidence against a causal relationship of trait 1 on trait 2.</li>
<li>Do many of the shared SNPs have the same angle? This may be indicative of a single shared factor or a causal relationship.</li>
</ul>
</div>
</div>
<div id="estimating-the-distribution-of-theta_i-vert-r_i-0" class="section level2">
<h2>Estimating the distribution of <span class="math inline">\(\theta_i \vert r_i &gt; 0\)</span></h2>
<p>We start by writing the joint pdf of <span class="math inline">\(\hat{r_i}\)</span> and <span class="math inline">\(\hat{\theta_i}\)</span> given <span class="math inline">\(r_i\)</span> and <span class="math inline">\(\theta_i\)</span>. We assume that <span class="math inline">\(\hat{\beta_{i,j}} \sim N(\beta_{i,j}, s_{ij}^2)\)</span> and that <span class="math inline">\(\beta_{i,j}\)</span> are independent both across SNPs and across traits. Later we can relax the need for independence across traits to account for shared samples.</p>
<p>In order to simplify the likelihood, we modify our earlier definitions of <span class="math inline">\(r\)</span>,<span class="math inline">\(\hat{r}\)</span>, <span class="math inline">\(\theta\)</span>, adn <span class="math inline">\(\hat{\theta}\)</span> to be defined in terms of <span class="math inline">\(z\)</span>-scores rather than effect sizes: <span class="math inline">\(\hat{r}_i = \sqrt{ \hat{z}_{i,1}^{2} + \hat{z}_{i,2}^2}\)</span> and <span class="math inline">\(\hat{\theta} = tan^{-1}(\hat{z}_{i,2}/\hat{z}_{i,1})\)</span> where <span class="math inline">\(z_{i,j} = \hat{\beta}_{i,j}/s_{i,j}\)</span>. With this modification, the interpretation of values of <span class="math inline">\(\theta_i\)</span> close to 0 and <span class="math inline">\(\pm \pi/2\)</span> remains the same.</p>
<p>If SNPs have approximately the same allele frequency between the two studies then <span class="math inline">\(s_{i,1} \approx k\cdot s_{i,2}\)</span> for some sample <span class="math inline">\(k\)</span> dependent on the sample sizes of the two studies. In this case, we would still expect a sharp peak in the distribution of angles of <span class="math inline">\(z\)</span>-scores in the case of a causal relationship. However, if the studies have different allele frequencies, there could be circumstances where many SNPs have the same angle on the effect size scale but somewhat different angles on the <span class="math inline">\(z\)</span>-score scale. If this difference becomes important, we may be able to implement a more complicated likelihood later.</p>
<p>With these defninitions and assumptions, we can write <span class="math display">\[ p(\hat{r}_i, \hat{\theta}_i \vert r_i , \theta) = \frac{\hat{r}_i}{2\pi} \exp \left( \frac{-1}{2}\left( \hat{r}_i^2 + r_i^2 - 2\hat{r}r\cos(\hat{\theta}_i-\theta_i) \right) \right)\]</span></p>
<p>We model the prior distribution of <span class="math inline">\(r\)</span> as a mixture of <span class="math inline">\(L+1\)</span> uniform distributions with left edge of support at 0: <span class="math display">\[ r \sim \gamma_0 \delta_0 + \sum_{i=1}^{k}\gamma_k U(r, 0, b_l).\]</span></p>
<p>The mixture parameters <span class="math inline">\(\gamma_0, \dots, \gamma_K\)</span> are hyper-parameters summing to 1 that can estimated emprically from the data following the ASH framework (discussed more later). We reduce distribution of <span class="math inline">\(\theta_i \vert r_i &gt;\)</span> to a grid of values <span class="math inline">\(\theta^{(1)}, \dots, \theta^{(L)} \in [-pi/2, \pi/2]\)</span>. We could place a uniform prior on these values or we could put more prior weight on <span class="math inline">\(0\)</span> and <span class="math inline">\(\pm \pi/2\)</span> reflecting our prior belief that most effect SNPs are not shared. Define <span class="math inline">\(p(\theta_i = \theta^{(l)} \vert r_i &gt; 0) = \alpha_l\)</span>.</p>
<p>We assume that <span class="math inline">\(r\)</span> and <span class="math inline">\(\theta\)</span> are independent. This assumption is likely to be false since we expect the distribution of <span class="math inline">\(z\)</span>-scores for the two traits to be different. However, our focus is on the distribution of <span class="math inline">\(\theta\)</span> so it is possible that our estimates may not be too sensitive to this assumption.</p>
<p>For each SNP, we can estimate the posterior distribution of <span class="math inline">\(\theta_i\)</span>. Note that since <span class="math inline">\(\theta\)</span> is not defined when <span class="math inline">\(r = 0\)</span>, <span class="math inline">\(p[\theta_i = \theta^{(l)}] = P[\theta_i = \theta^{(l)}, r_i &gt; 0]\)</span>. So <span class="math display">\[ P(\theta_i = \theta^{(l)}, r_i &gt; 0 \vert \hat{r}_i, \hat{\theta}_i) = P(\theta_i = \theta^{(l)} \vert \hat{r}_i, \hat{\theta}_i, r_i &gt; 0)P(r_i &gt; 0 \vert \hat{r}_i)\]</span> Note that the posterior distribution of <span class="math inline">\(r\)</span> depends only on <span class="math inline">\(\hat{r}\)</span>. This will be discussed further on. For SNP <span class="math inline">\(i\)</span>, the posterior probability that <span class="math inline">\(\theta_i \theta^{(l)}\)</span> conditional on <span class="math inline">\(r_i &gt;0\)</span> is <span class="math display">\[ P(\theta_i = \theta^{(l)} \vert \hat{r}_i, \hat{\theta}_i, r_i &gt; 0) \propto P(\hat{r}_i, \hat{\theta}_i \vert \theta_i=\theta^{(l)}, r_i &gt; 0) P(\theta = \theta^{(l)} \vert  r &gt; 0)\]</span> where <span class="math display">\[ P(\hat{r}, \hat{\theta} \vert \theta^{(l)}, r &gt; 0) = \frac{1}{\sum_{k=1}^{K}\gamma_k} \sum_{k=1}^{K} \frac{\gamma_k}{b_k}\int_{0}^{r}P(\hat{r}, \hat{\theta} \vert r, \theta=\theta^{(l)}) dr\]</span> We can compute the integral above numerically. From these, we can find the posterior probability that any SNP has angle <span class="math inline">\(\theta^{(l)}\)</span> as</p>
<p><span class="math display">\[
P(\theta = \theta^{(l)}) = \sum_{i=1}^{p} P(\theta_i = \theta^{(l)} \vert \hat{r}_i, \hat{\theta}_i, r_i &gt; 0) P(r_i &gt; 0 \vert \hat{r}_i)
\]</span> These can then be normalized to the conditional probabilities <span class="math inline">\(P(\theta = \theta^{(l)}\vert r &gt; 0)\)</span>.</p>
</div>
<div id="estimating-gamma_0-dots-gamma_k-and-the-posterior-probability-of-r_i-0-vert-hatr." class="section level2">
<h2>Estimating <span class="math inline">\(\gamma_0, \dots, \gamma_K\)</span> and the posterior probability of <span class="math inline">\(r_i &gt; 0 \vert \hat{r}\)</span>.</h2>
<p>The marginal pdf of <span class="math inline">\(\hat{r}\)</span> given <span class="math inline">\(r\)</span> and <span class="math inline">\(\theta\)</span> does not depend on <span class="math inline">\(\theta\)</span> and can be written as <span class="math display">\[
p(\hat{r}_i \vert r_i ) = \hat{r}\exp\left(\frac{-1}{2}\left(\hat{r}^{2} + r^{2}\right)\right)I_0(\hat{r}r)
\]</span> Where <span class="math inline">\(I_o\)</span> is the modified Bessel function of order 0 <span class="math inline">\(I_0(x) = \int_0^{2\pi}e^{x\cos(\theta)}d\theta\)</span>.</p>
<p>With this likelihood, we can estimate <span class="math inline">\(\gamma_0, \dots, \gamma_K\)</span> by maximizing the likelihood <span class="math display">\[
L(\gamma) = \prod_{i=1}^p \left( \gamma_0 p(\hat{r}_i \vert r_i = 0 ) + \sum_{k=1}^{K}\frac{\gamma_k}{b_k} \int_{0}^{b_k} p(\hat{r}_i \vert r) dr \right)
\]</span> with a penalty encouraging more weight to <span class="math inline">\(\delta_0\)</span>.</p>
<p>From this, we compute the posterior probability that <span class="math inline">\(r_i &gt; 0\)</span> as <span class="math display">\[
\frac{\sum_{k=1}^{K}\frac{\hat{\gamma}_k}{b_k} \int_{0}^{b_k} p(\hat{r}_i \vert r) dr}{\hat{\gamma}_0 p(\hat{r}_i \vert r_i = 0 ) + \sum_{k=1}^{K}\frac{\hat{\gamma}_k}{b_k} \int_{0}^{b_k} p(\hat{r}_i \vert r) dr}.
\]</span></p>
</div>
<div id="experiments" class="section level2">
<h2>Experiments</h2>
<p>We start with a few simple experiments in which <span class="math inline">\(r\)</span> actually follows a mixture of uniform distribution and the signal is strong:</p>
<p>Example 1: theta uniformly distributed between 0 and <span class="math inline">\(pi/2\)</span>:</p>
<pre class="r"><code>library(bvpolar)
library(matrixStats)
set.seed(16382)
g0 &lt;- list(&quot;pi&quot;=c(0.8, 0.1, 0.1), a=rep(0, 3), b=c(0, 2, 5))
class(g0) &lt;- &quot;unimix&quot;
#generate true radius
r &lt;- runimix(n=1000, g=g0)
#generate true angle
theta &lt;- runif(1000, 0, pi/2)
#generate true z values (beta/sd)
z1 &lt;- r*cos(theta)
z2 &lt;- r*sin(theta)
#observed z-scores
zhat1 &lt;- rnorm(1000, z1, 1)
zhat2 &lt;- rnorm(1000, z2, 1)
#Re-orient so that zhat1 &gt; 0:
zhat2 &lt;- sign(zhat1)*zhat2
zhat1 &lt;- abs(zhat1)
#observed polar coordinates
rhat &lt;- sqrt(zhat1^2 + zhat2^2)
thetahat &lt;- atan2(zhat2, zhat1)
plot(zhat1, zhat2); abline(h=0, v=0)</code></pre>
<p><img src="polar_intro_files/figure-html/example1-1.png" width="672" /></p>
<pre class="r"><code>#Estimate gammas
fit_r &lt;- polar_est_r_mixture_uni(rhat, g=NULL, prior=NULL)</code></pre>
<pre><code>## 1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16</code></pre>
<pre class="r"><code>cbind(fit_r$fitted_g$b, fit_r$fitted_g$pi)[zapsmall(fit_r$fitted_g$pi) &gt; 0,]</code></pre>
<pre><code>##          [,1]       [,2]
## [1,] 0.000000 0.82929364
## [2,] 2.192724 0.03003493
## [3,] 3.100981 0.09776576
## [4,] 4.385449 0.01284735
## [5,] 6.201961 0.03005832</code></pre>
<p>We have done an ok job of recovering the distribution or <span class="math inline">\(r\)</span>.</p>
<pre class="r"><code>#Estimate thetas
tvals &lt;- seq(-1/2, 1/2, length.out=21)*pi
tprior &lt;- rep(c(10, 1, 10, 1, 10), c(1, 9, 1, 9, 1))
fit_t &lt;- polar_est_t(rhat, thetahat, fit_r, tvals, tprior, orient=T)</code></pre>
<pre><code>## 1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21</code></pre>
<pre class="r"><code>plot(tvals, fit_t$mix_overall, type=&quot;b&quot;, xlab=&quot;theta&quot;, ylab=&quot;Posterior&quot;)</code></pre>
<p><img src="polar_intro_files/figure-html/example1part3-1.png" width="672" /></p>
<p>We have successfuly recovered a pattern indicating that most values of theta are between 0 and <span class="math inline">\(\pi/2\)</span>. We can also look at the distribution of estimates of <span class="math inline">\(p(r_i &gt; 0 \vert \hat{r}_i)\)</span>.</p>
<pre class="r"><code>#Estimate thetas
hist(fit_t$wts, xlab=&quot;Post. prob. r postive&quot;, main=&quot;Posterior probability that r &gt; 0&quot;)</code></pre>
<p><img src="polar_intro_files/figure-html/example1part4-1.png" width="672" /></p>
<pre class="r"><code>plot(fit_t$wts, jitter(as.numeric(r &gt; 0)), xlab=&quot;Post. prob. r postive&quot;, ylab=&quot;truth: r positive?&quot;)</code></pre>
<p><img src="polar_intro_files/figure-html/example1part4-2.png" width="672" /></p>
<p>We can also see how we would have done if we knew the distribution of <span class="math inline">\(r\)</span>:</p>
<pre class="r"><code>fit_r_oracle &lt;- fit_r
fit_r_oracle$fitted_g &lt;- g0
fit_t_oracle &lt;- polar_est_t(rhat, thetahat, fit_r_oracle, tvals, tprior, orient=T)</code></pre>
<pre><code>## Warning in pihat * matrix_lik: longer object length is not a multiple of
## shorter object length</code></pre>
<pre><code>## 1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21</code></pre>
<pre class="r"><code>plot(tvals, fit_t_oracle$mix_overall, type=&quot;b&quot;, xlab=&quot;theta&quot;, ylab=&quot;Posterior&quot;, main=&quot;Dist of r known&quot;)</code></pre>
<p><img src="polar_intro_files/figure-html/example1part5-1.png" width="672" /></p>
<p>These results are quite similar.</p>
<p>In another example, we analyze simulated data produced for previous simulations. These were produced under the sharing model parameterized by <span class="math inline">\(q\)</span> and <span class="math inline">\(b\)</span> described here: <a href="https://jean997.github.io/sh2Ash/mh_test.html" class="uri">https://jean997.github.io/sh2Ash/mh_test.html</a>. I looked at only three realizations generated from this model. One is produced under the “null” model in which <span class="math inline">\(q = 0\)</span> and any shared effects between the traits are random (and rare). One is produced under the causal model in which <span class="math inline">\(q = 1\)</span> and <span class="math inline">\(b = 0.5\)</span> (a fairly strong effect) and one is produced under a model with some sharing, with <span class="math inline">\(q = 0.2\)</span> and <span class="math inline">\(b=0.5\)</span>.</p>
<p>Posterior distributions of <span class="math inline">\(\theta\)</span> for the three examples are shown below:</p>
<p><img src="polar_first_results.png" width="400"></p>
<p>Encouragingly, the estimates for the causal model have much less mass at zero than the estimates for the other two models. This provides evidence that most variants affecting trait 1 also affect trait 2. Additionally, the estimates for the causal model have a spike between 0 and <span class="math inline">\(pi/2\)</span> indicating that many variants have a similar angle providing further evidence for a causal model. By contrast, the two non-causal simulations both have a peak at zero indicating that there are many variants indicating only trait 1.</p>
</div>

<hr>
<p>
    This <a href="http://rmarkdown.rstudio.com">R Markdown</a> site was created with <a href="https://github.com/jdblischak/workflowr">workflowr</a>
</p>
<hr>

<!-- To enable disqus, uncomment the section below and provide your disqus_shortname -->

<!-- disqus
  <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'rmarkdown'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
-->


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
