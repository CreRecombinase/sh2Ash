<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Jean Morrison" />

<meta name="date" content="2017-11-24" />

<title>Subsetting SNPs; Dealing with LD</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlightingOnLoad(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Sherlock2 model using Ash</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/jdblischak/workflowr">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Subsetting SNPs; Dealing with LD</h1>
<h4 class="author"><em>Jean Morrison</em></h4>
<h4 class="date"><em>2017-11-24</em></h4>

</div>


<!-- The file analysis/chunks.R contains chunks that define default settings
shared across the workflowr files. -->
<!-- Update knitr chunk options -->
<!-- Insert the date the file was last updated -->
<!-- Insert the code version (Git commit SHA1) if Git repository exists and R
 package git2r is installed -->
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>In <a href="subset_snps.html">this</a> analysis, we determined that using the top 1% of SNPs only seemed like a viable option in a setting with no LD. In this anlysis, my goal is to determine if this is also reasonable.</p>
<p>LD complicates this question in two ways:</p>
<ol style="list-style-type: decimal">
<li><p>With LD, the true likelihood is too difficult to calculate so we have been approximating it using a weighted pseudo-likelihood. Results <a href="pseudo_likelihood.html">here</a> indicate that if the effect sizes are sparse, weights of <span class="math inline">\(w_j = \left( \sum_{ij} r_{ij}^2 \right)^{-1}\)</span> may work well for approximating the posterior but may not be the best choice if true effects are not sparse.</p></li>
<li><p>With LD, there are many possible ways that we could choose a set of ``top SNPs’’. In this analysis I will experiment with choosing a set of SNPs in minimal LD with each other.</p></li>
</ol>
<p>In these explorations we will use two test data sets. Both have 100,000 SNPs falling into 299 LD blocks. LD structure is taken from Wen and Stephens estimates of LD from the 1,000 genomes European cohort. Data set S is generated under the shared model with <span class="math inline">\(q=0.5\)</span> and <span class="math inline">\(b=0.4\)</span>. Data set C genrated under the causal model with <span class="math inline">\(q=1\)</span> and <span class="math inline">\(b=0.4\)</span>.</p>
</div>
<div id="distribution-of-true-effect-sizes" class="section level2">
<h2>Distribution of true effect sizes</h2>
<p>In our model without LD, we assume that, conditional on the true effects, effect size estimates are independent. That is, we assume that <span class="math display">\[ \hat{\beta}_k \sim N(\beta_k, S_k^{2})\]</span> where <span class="math inline">\(\hat{\beta}_k\)</span> is the <span class="math inline">\(p\)</span>-vector of effect size estimates for study <span class="math inline">\(k \in \lbrace 1, 2 \rbrace\)</span>, <span class="math inline">\(\beta_k\)</span> are the vectors of true effects and <span class="math inline">\(S_k\)</span> is a diagonal matrix with <span class="math inline">\((S_k)_{jj} = se(\hat{\beta}_{kj})\)</span>. We assume that the correlation between <span class="math inline">\(\hat{\beta}_{1i}\)</span> and <span class="math inline">\(\hat{\beta}_{2j}\)</span> is 0 if <span class="math inline">\(i\neq j\)</span> and <span class="math inline">\(\rho\)</span> if <span class="math inline">\(i=j\)</span>.</p>
<p>If there is LD then, using results from Zhu and Stephens (2016), <span class="math display">\[ \hat{\beta}_k \sim N(S_k R S_k^{-1} \beta_k, S_kRS_k),\]</span> where <span class="math inline">\(R\)</span> is the correlation matrix between SNPs. For simplicity, we assume the same LD between the two studies. We define the LD trasformed effects as <span class="math display">\[ \tilde{\beta}_k = S_k R S_k^{-1} \beta_k. \]</span> If <span class="math inline">\(R\)</span> is block diagonal and the effects in both studies are sparse, we might expect that most of the time there will be at most one effect in either study within an LD block.</p>
<p>If the true effects are described by the “b-q” model we have talked about previously, then <span class="math display">\[   \beta_{2j} = b\beta_{1j}Z_j + \gamma_j, \]</span> where <span class="math inline">\(b\)</span> is the effect size of the shared factor on trait 1, <span class="math inline">\(Z_j \sim Bern(q)\)</span> and <span class="math inline">\(\gamma_j\)</span> is the effect of SNP <span class="math inline">\(j\)</span> directly on trait 2 and not through the shared factor, <span class="math inline">\(\gamma_j \sim g(\pi_2, \sigma)\)</span> where <span class="math inline">\(g\)</span> is an ash distribution with mixture parameters <span class="math inline">\(\pi_2\)</span> and grid of variances <span class="math inline">\(\sigma\)</span>. Therefore, <span class="math display">\[ \tilde{\beta}_2 = b S_2 R S_2^{-1} (\beta_1 \circ Z) + S_2 R S_2^{-1} \gamma. \]</span></p>
<p>If each SNP has the same allele frequency in the two studies then <span class="math inline">\(S_2 = c S_1\)</span> where <span class="math inline">\(c\)</span> is a constant that depends on the sample sizes of the two studies. In this case, we can re-write the relationship above as <span class="math display">\[ \tilde{\beta}_2 = b S_1 R S_1^{-1} (\beta_1 \circ Z) + S_2 R S_2^{-1} \gamma. \]</span></p>
<p>Now assume that <span class="math inline">\(R\)</span> is block diagonal and can be decomposed into <span class="math inline">\(B\)</span> blocks. We use <span class="math inline">\(p_b\)</span> to indicate the number of SNPs in block <span class="math inline">\(b\)</span> so <span class="math inline">\(\sum_{b=1}^{B}p_b = p\)</span>. If <span class="math inline">\(x\)</span> is a <span class="math inline">\(p\)</span>-vector then we will use <span class="math inline">\(x_b\)</span> to indicate the <span class="math inline">\(p_b\)</span>-vector of elements corresponding to SNPs in block <span class="math inline">\(b\)</span>. If true effects for the two traits are sparse enough that there is at most one effect from either study within an LD block then</p>
<p><span class="math display">\[ \tilde{\beta}_{2,b} = b \tilde{\beta}_{1,b} \tilde{Z}_b + S_2 R S_2^{-1} \gamma_b, \]</span> where <span class="math inline">\(\tilde{Z}_b\)</span> is an indicator that any SNP in block <span class="math inline">\(b\)</span> acts through the shared factor and <span class="math inline">\(Z_b \sim Bern(q)\)</span>. This means that under the special conditions that</p>
<ul>
<li><span class="math inline">\(R\)</span> is block diagonal</li>
<li>LD is the same between studies</li>
<li>Allele frequencies are the same between studies</li>
<li>There is at most one effect in either study per LD block</li>
</ul>
<p>we can use summary statistics from studies with LD to estimate the same parameters we were able to estimate in the case without LD. We can maximize the same likelihood we used in the case without LD to obtain unbiased point estimates of <span class="math inline">\(b\)</span> and <span class="math inline">\(q\)</span>.</p>
<p>This does not, however, account for correlation between effect size estimates for different SNP which will effect our estimates of the posterior distributions of <span class="math inline">\(b\)</span> and <span class="math inline">\(q\)</span>. If SNPs are independent, we can write the total likelihood as <span class="math display">\[L(\hat{\beta}_1, \hat{\beta}_2 \vert b, q, \rho, S_1, S_2, \theta)  = \prod_{j=1}^{p} L(\hat{\beta}_{1,j}, \hat{\beta}_{2,j} \vert b, q, \rho, (S_1)_{jj}, (S_2)_{jj}, \theta).\]</span> Here, the hyper-parameter <span class="math inline">\(\theta\)</span> includes the mixture proportions and grids of variances for the ash prior distributions of <span class="math inline">\(\beta_{1}\)</span> and <span class="math inline">\(\gamma\)</span>.</p>
<p>In the presence of LD, this no longer holds. We have taken an approach similar to that of Liley et al (2016). We construct a “pseudo-log likelihood” as a weighted sum of the log likelihoods for each SNP. <span class="math display">\[PL(\hat{\beta}_1, \hat{\beta}_2 \vert b, q, \rho, S_1, S_2, \theta)  = \prod_{j=1}^{p} \left(L(\hat{\beta}_{1,j}, \hat{\beta}_{2,j} \vert b, q, \rho, (S_1)_{jj}, (S_2)_{jj}, \theta) \right)^{w_j}.\]</span> Here, <span class="math inline">\(w_j\)</span> captures the amount of LD between SNP <span class="math inline">\(j\)</span> and other SNPs. We set <span class="math inline">\(w_j\)</span> equal to the inverse of the LD score, <span class="math inline">\(w_j = \frac{1}{\sum_{i\in S_b} r_{ij}^2}\)</span> where <span class="math inline">\(b\)</span> is the LD block containing SNP <span class="math inline">\(j\)</span>.</p>
<p>We then estimate a “pseudo-poseterior” distribution for <span class="math inline">\(b\)</span> and <span class="math inline">\(q\)</span> by assuming independent priors for <span class="math inline">\(b\)</span> and <span class="math inline">\(q\)</span> <span class="math inline">\(P_b\)</span> and <span class="math inline">\(P_q\)</span> and defining <span class="math display">\[
P(b, q \vert \rho, \hat{\beta}_1, \hat{\beta}_2, S_1, S_2, \theta ) \propto  PL(\hat{\beta}_1, \hat{\beta}_2 \vert b, q, \rho, S_1, S_2, \theta) \cdot P(b) \cdot P(q)
\]</span></p>
</div>
<div id="distributions-of-ld-transformed-effect-sizes-in-data" class="section level2">
<h2>Distributions of LD transformed effect sizes in data</h2>
<p>In reality, the four conditions above will not hold exactly. This means that the model of <span class="math display">\[ \tilde{\beta}_{2,b} = b \tilde{\beta}_{1,b} \tilde{Z}_b + S_2 R S_2^{-1} \gamma_b, \]</span> is an approximation. We can look at the joint distribution of LD transformed effect sizes in the simulated data sets. Below, I show the tue and LD transformed effects for the two data sets. We can see that in the LD transformed effects, there are many more SNPs that have non-zero effects on both traits and that not all of these lie on the line with slope <span class="math inline">\(b\)</span>.</p>
<p><img src="figure/subset_snps_ld.Rmd/ll_known-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>In the following experiments, the distribution of  direct effects and <span class="math inline">\(\rho\)</span> are estimated from the data using all SNPs and assuming <span class="math inline">\(b = q = 0\)</span>.</p>
</div>
<div id="posterior-distribution-using-all-snps-and-weights" class="section level2">
<h2>Posterior distribution using all SNPs and weights</h2>
<p>We first calculate the posterior distribution using all SNPs and the LD weights. Below I show plots of the marginal posteriors for <span class="math inline">\(b\)</span> and <span class="math inline">\(q\)</span>.</p>
<p><img src="figure/subset_snps_ld.Rmd/all_posterior_plot-1.png" width="1056" style="display: block; margin: auto;" /></p>
<p>Under the shared model, the distribution of <span class="math inline">\(q\)</span> is shifted farther to the right for data set C than for data set S but it is not nearly as peaked as it was using <a href="subset_snps.html">the data with no LD</a>.</p>
<p>Using all SNPs, the <span class="math inline">\(z\)</span>-score comparing the shared model to the causal model for data set C is -2.49. For data set S it is -0.55 with negative <span class="math inline">\(z\)</span>-scores favoring the causal model.</p>
</div>
<div id="posterior-distribution-using-all-snps-and-no-weights" class="section level2">
<h2>Posterior distribution using all SNPs and no weights</h2>
<p><img src="figure/subset_snps_ld.Rmd/all_posterior_plot_nowts-1.png" width="1056" style="display: block; margin: auto;" /></p>
<p>Without the weights, the posterior distributions are much more peaked and farther from the priors. They also show a much clearer difference between the two data sets. The <span class="math inline">\(z\)</span>-score comparing the shared model to the causal model for data set C is -1.44. For data set S it is 0.77 with negative <span class="math inline">\(z\)</span>-scores favoring the causal model. The evidence in favor of the causal model from data set C is now weaker because the posterior is more similar to the causal model.</p>
</div>
<div id="posterior-using-oracle-snps-and-no-wetghts" class="section level2">
<h2>Posterior using oracle SNPs and no wetghts</h2>
<p>Both data sets have 72 SNPs that causally effect trait 1. We assume that, for the most part, these SNPs are not in LD with each other (they are chosen randomly from the 10,000 SNPs in the data) and therefore don’t include the weights when we calculate the oracle posterior. For the distribution of direct effects, we start with the distribution estimated using all SNPs and condition on the effect for trait 1 not being zero.</p>
<pre><code>seed:  720903897 
Model 2.
Model 3.</code></pre>
<pre><code>seed:  546569365 
Model 2.
Model 3.</code></pre>
<p><img src="figure/subset_snps_ld.Rmd/oracle_posterior-1.png" width="1056" style="display: block; margin: auto;" /></p>
<p>The posterior using only the true effect SNPs is not as peaked as the posterior using all SNPs and no weights. This makes sense because, with LD, there is additional noise. The effect estimates aren’t estimating the true effect sizes but the LD transformed effect sizes.</p>
</div>
<div id="posterior-distribution-using-top-snps-in-weak-ld-no-weights" class="section level2">
<h2>Posterior distribution using top SNPs in weak LD, no weights</h2>
<p>If we can conduct the analysis using only top trait 1 SNPs that are in weak LD we can make a better case for ignoring LD in the analysis. As before, we will use the distribution of direct effects estimated from all SNPs.</p>
<p>If we prune for LD so that all SNPs have pairwise correlation of less than 0.1 (<span class="math inline">\(r^2 &lt; 0.01\)</span>) preferentially choosing SNPs with the lowest trait 1 <span class="math inline">\(p\)</span>-values, we retain 10482 SNPs in data set C and 10484 in data set S.</p>
<pre><code>seed:  723285923 
Model 2.
Model 3.</code></pre>
<pre><code>seed:  748994525 
Model 2.
Model 3.</code></pre>
<p><img src="figure/subset_snps_ld.Rmd/top_snps_posterior-1.png" width="672" style="display: block; margin: auto;" /> These posteriors are more peaked than the oracle posterior and farther from the prior but less than the posteriors using all SNPs and no weights. From this analysis <span class="math inline">\(z\)</span>-score comparing the shared model to the causal model for data set C is -0.29. For data set S it is -0.22.</p>
<p>We might wonder if it is important to select the LD pruned SNP set favoring SNPs with low trait 1 p-values. We could try instead, choosing random LD pruned SNP sets.</p>
<pre><code>seed:  7302518 
Model 2.
Model 3.</code></pre>
<pre><code>seed:  579237478 
Model 2.
Model 3.</code></pre>
<p><img src="figure/subset_snps_ld.Rmd/random_snps-1.png" width="1056" style="display: block; margin: auto;" /> Using a random set of SNPs, the posterior distribution of <span class="math inline">\(q\)</span> is much farther from the truth. The <span class="math inline">\(z\)</span>-score comparing the shared model to the causal model for data set C is -0.22. For data set S it is -0.77.</p>
</div>
<div id="simulation-results" class="section level2">
<h2>Simulation results</h2>
<p>I compared three methods in simulations:</p>
<ul>
<li>Estimate posterior and calculate <span class="math inline">\(z\)</span>-score using all SNPs and LD weights</li>
<li>Estimate posterior and calculate <span class="math inline">\(z\)</span>-score using all SNPs and no LD weights</li>
<li>Estimate posterior and calculate <span class="math inline">\(z\)</span>-score using LD pruned subset of SNPs (pruning favors low trait 1 p-values)(usually keeps about 10% of SNPS)</li>
<li>Estimate posterior and calculate <span class="math inline">\(z\)</span>-score using top 1000 (1% of total) LD pruned SNPs based on trait 1 p-values.</li>
</ul>
<p>I ran 20 simulations for each of seven values of <span class="math inline">\(q\)</span>. Below, I show the number of simulations for which <span class="math inline">\(z &lt; \Phi(\alpha)\)</span> with <span class="math inline">\(\alpha\)</span> equal to 0.9, 0.95 and 0.975.</p>
<p><img src="num_pos_2017-11-27.png" width="700"></p>
<p>The method using all SNPs and weights has more false postives than the other methods for small values of <span class="math inline">\(q\)</span>. The LD pruning methods have better type 1 error than the method using all SNPs for most values of <span class="math inline">\(q\)</span> values of <span class="math inline">\(\alpha\)</span>. These methods also have slightly worse power when <span class="math inline">\(q = 1\)</span>. For <span class="math inline">\(\alpha = 0.9\)</span>, both LD pruning methods and the method using all snps and no weights have the same power. At <span class="math inline">\(\alpha=0.95\)</span> the LD pruning method using more SNPs and the method using all SNPs have the same power (18/20) while the top 1% method detects 16 of the 20 true positives. When <span class="math inline">\(\alpha=0.975\)</span>, both LD pruning methods detect only 15 of the 20 true positives while the method using all SNPs and no weights detects 18.</p>
</div>
<div id="session-information" class="section level2">
<h2>Session information</h2>
<!-- Insert the session information into the document -->
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 3.4.1 (2017-06-30)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 17.04

Matrix products: default
BLAS: /usr/lib/libblas/libblas.so.3.7.0
LAPACK: /usr/lib/lapack/liblapack.so.3.7.0

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] knitr_1.17        cumstats_1.0      gridExtra_2.2.1   sherlockAsh_0.1.0
[5] ggplot2_2.2.1     tidyr_0.6.3      

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.13        compiler_3.4.1      plyr_1.8.4         
 [4] iterators_1.0.8     tools_3.4.1         digest_0.6.12      
 [7] MHadaptive_1.1-8    evaluate_0.10.1     tibble_1.3.1       
[10] gtable_0.2.0        lattice_0.20-35     rlang_0.1.1        
[13] Matrix_1.2-10       foreach_1.4.3       DBI_0.6-1          
[16] yaml_2.1.14         parallel_3.4.1      loo_1.1.0          
[19] dplyr_0.5.0         stringr_1.2.0       stats4_3.4.1       
[22] rprojroot_1.2       grid_3.4.1          R6_2.2.1           
[25] rmarkdown_1.7       ashr_2.1-27         magrittr_1.5       
[28] backports_1.1.0     scales_0.4.1        codetools_0.2-15   
[31] htmltools_0.3.6     matrixStats_0.52.2  MASS_7.3-47        
[34] assertthat_0.2.0    colorspace_1.3-2    numDeriv_2016.8-1  
[37] labeling_0.3        stringi_1.1.5       RcppParallel_4.3.20
[40] lazyeval_0.2.0      munsell_0.4.3       doParallel_1.0.11  
[43] pscl_1.5.1          truncnorm_1.0-7     SQUAREM_2016.8-2   </code></pre>
</div>

<hr>
<p>
    This <a href="http://rmarkdown.rstudio.com">R Markdown</a> site was created with <a href="https://github.com/jdblischak/workflowr">workflowr</a>
</p>
<hr>

<!-- To enable disqus, uncomment the section below and provide your disqus_shortname -->

<!-- disqus
  <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'rmarkdown'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
-->


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
